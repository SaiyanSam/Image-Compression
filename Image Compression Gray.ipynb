{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee81515b-32a8-4da4-bb7c-42e3d42415f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf79c9c-2f61-4a1d-8cc9-6c8497d48099",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/penguin.png'\n",
    "image = Image.open(image_path).convert('L')\n",
    "\n",
    "image.save(\"images/penguin_original.jpg\", \"JPEG\")\n",
    "\n",
    "image_data = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a0410-fa6b-4c48-a7c9-76b899958673",
   "metadata": {},
   "source": [
    "## Compression Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1ce25-5fbc-406f-9a62-73fb4d585292",
   "metadata": {},
   "source": [
    "The split_into_blocks() function will split the entire image into smaller **non-overlapping** 8x8 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9445c-2263-4cbe-9e19-68f7ad8f579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_blocks(channel, block_size=8):\n",
    "    h, w = channel.shape\n",
    "    blocks = []\n",
    "    for i in range(0, h, block_size):\n",
    "        for j in range(0, w, block_size):\n",
    "            block = channel[i:i+block_size, j:j+block_size]\n",
    "            if block.shape == (block_size, block_size):\n",
    "                blocks.append(block)\n",
    "    return np.array(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d553bb4a-b7f5-482f-92b6-c952364c7a9b",
   "metadata": {},
   "source": [
    "The apply_dct() function will apply Discrete Cosine Transformation (DCT) to each of the 8x8 image blocks, thereby transforming the image from spatial to frequency domain.\n",
    "- Each block is being transformed using dct(block.T, norm='ortho').T, which performs 2D DCT by applying to the **rows first, and thn to the columns**.\n",
    "- The **norm='ortho'** normalizes the DCT, ensuring the energy is evenly distributed.\n",
    "- The result is a **8x8 block containing frequency coefficients**, where the lower frequencies are concentrated in the top-left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5bda90-d3b3-4f12-b60e-ceac01e73641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dct(blocks):\n",
    "    dct_blocks = []\n",
    "    for block in blocks:\n",
    "        dct_block = dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "        dct_blocks.append(dct_block)\n",
    "    return np.array(dct_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0cc74-9766-4549-bf6c-52d372c6dcf3",
   "metadata": {},
   "source": [
    "The quantize() function is applied to the block of DCT coefficients, and is a **lossy** procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b948f89-2f17-48cc-8d43-43fd09c7642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization matrix for grayscale images\n",
    "quant_matrix = np.array([\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f055a-fa85-4301-ba58-4891985fa681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(blocks, quant_matrix):\n",
    "    quantized_blocks = []\n",
    "    for block in blocks:\n",
    "        quantized_block = np.round(block / quant_matrix).astype(int)\n",
    "        quantized_blocks.append(quantized_block)\n",
    "    return np.array(quantized_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62bad2d-30b6-4bb1-8678-cd5bb6a34ea7",
   "metadata": {},
   "source": [
    "The zigzag_order() function arranges the Quantized DCT Coefficients in a **1D order**, with lower indices occupied by lower frequency coeeficients.\n",
    "\n",
    "Prepares the data for Run-Length Encoding (RLE) and Huffman encoding in standard JPEG compression, making it easier to compress long runs of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7c1808-68fe-4529-862e-ae6e00b4ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_order(block):\n",
    "    zigzag_pattern = np.array([\n",
    "        [0, 1, 5, 6, 14, 15, 27, 28],\n",
    "        [2, 4, 7, 13, 16, 26, 29, 42],\n",
    "        [3, 8, 12, 17, 25, 30, 41, 43],\n",
    "        [9, 11, 18, 24, 31, 40, 44, 53],\n",
    "        [10, 19, 23, 32, 39, 45, 52, 54],\n",
    "        [20, 22, 33, 38, 46, 51, 55, 60],\n",
    "        [21, 34, 37, 47, 50, 56, 59, 61],\n",
    "        [35, 36, 48, 49, 57, 58, 62, 63]\n",
    "    ]).flatten()\n",
    "    return block.flatten()[zigzag_pattern]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d966ede-17bc-4d37-9290-63fd5df23b34",
   "metadata": {},
   "source": [
    "The pad_image() function was added for images whose **dimensions are not perfectly divisible by 8**. The motivation was from the experimenatal phase where we passed such images and the code was not able to process such images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ec4a9d-3e91-44b5-a4f6-8ab578d4af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, block_size=8):\n",
    "    h, w = image.shape\n",
    "    pad_h = (block_size - h % block_size) % block_size\n",
    "    pad_w = (block_size - w % block_size) % block_size\n",
    "    padded_image = np.pad(image, ((0, pad_h), (0, pad_w)), mode='constant', constant_values=0)\n",
    "    return padded_image, padded_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7bf3d-6448-4240-8edf-7b0ead38b1ce",
   "metadata": {},
   "source": [
    "## Decompression Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb8ae9-fe7a-4d50-8039-5766f13425f5",
   "metadata": {},
   "source": [
    "The inverse_quantize() function **scales** the Quantized DCT Coefficients back up via multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b58f0-70f7-4d81-9d90-e0e9de4d1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_quantize(blocks, quant_matrix):\n",
    "    return np.array([block * quant_matrix for block in blocks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce0a3c-fe28-4e37-8c47-e58bd012b379",
   "metadata": {},
   "source": [
    "The apply_idct() function transforms the frequency domain data **back to spatial domain** pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9fd36-57c7-492e-bc15-7ca5ae0acbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_idct(blocks):\n",
    "    return np.array([idct(idct(block.T, norm='ortho').T, norm='ortho') for block in blocks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467d6d-48aa-49f4-bd63-d6a98f6a4aa3",
   "metadata": {},
   "source": [
    "The reconstruct_image_from blocks() function will reaasemble the 8x8 blocks into the final image.\n",
    "- padded_shape will be passed as image_shape argument to avoid partial blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0dcca5e-6b19-4c40-b43a-a145da3bff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image_from_blocks(blocks, image_shape, block_size=8):\n",
    "    h, w = image_shape\n",
    "    image = np.zeros((h, w))\n",
    "    block_index = 0\n",
    "    for i in range(0, h, block_size):\n",
    "        for j in range(0, w, block_size):\n",
    "            image[i:i+block_size, j:j+block_size] = blocks[block_index]\n",
    "            block_index += 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1667a592-0d68-4345-a4fe-87eeff692dc5",
   "metadata": {},
   "source": [
    "## Compression steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d09806-4b99-449d-9c72-f17f0b087208",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_image, padded_shape = pad_image(image_data)\n",
    "blocks = split_into_blocks(padded_image)\n",
    "dct_blocks = apply_dct(blocks)\n",
    "quantized_blocks = quantize(dct_blocks, quant_matrix)\n",
    "zigzag_blocks = [zigzag_order(block) for block in quantized_blocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ff37c-8ace-4268-b075-9bbae88c28d7",
   "metadata": {},
   "source": [
    "## Decompression steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9558bc6c-74a5-4a59-94da-242c27cde54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_blocks = inverse_quantize(quantized_blocks, quant_matrix)\n",
    "idct_blocks = apply_idct(dequantized_blocks)\n",
    "reconstructed_image = reconstruct_image_from_blocks(idct_blocks, padded_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef2a2b-4948-416c-9c69-ad32a1c647d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f7f6dc-3f86-4bb0-aceb-d4e1416654b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed image saved as reconstructed_image.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# To ensure pixel values are in the correct range (0 to 255)\n",
    "reconstructed_image_clipped = np.clip(reconstructed_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# To convert the array to an Image object and save it as a JPEG\n",
    "reconstructed_img = Image.fromarray(reconstructed_image_clipped, mode='L')\n",
    "reconstructed_img.save(\"images/reconstructed_image.jpg\", \"JPEG\")\n",
    "print(\"Reconstructed image saved as reconstructed_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30798f6c-ec68-4872-9eea-8a0782298328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31e80ef-3c1f-493f-a29c-b309b247fce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image Size: 5290002 bytes\n",
      "Compressed Image Size: 409353 bytes\n",
      "Space Saved: 4880649 bytes (92.26%)\n",
      "Compression Ratio: 12.92\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "original_size = os.path.getsize(\"images/penguin.png\")\n",
    "print(f\"Original Image Size: {original_size} bytes\")\n",
    "\n",
    "compressed_size = os.path.getsize(\"images/reconstructed_image.jpg\")\n",
    "print(f\"Compressed Image Size: {compressed_size} bytes\")\n",
    "\n",
    "space_saved = original_size - compressed_size\n",
    "compression_ratio = original_size / compressed_size\n",
    "space_saved_percentage = (space_saved / original_size) * 100\n",
    "\n",
    "print(f\"Space Saved: {space_saved} bytes ({space_saved_percentage:.2f}%)\")\n",
    "print(f\"Compression Ratio: {compression_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c17a45-7e99-44de-be48-5dfd136509bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
